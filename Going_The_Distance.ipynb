{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPgBaQLxQfoj"
   },
   "source": [
    "## Going the Distance\n",
    "Uses the PPO actor-critic method to train a neural network to control a simple robot in the RacingCar environment from OpenAI gym (https://gym.openai.com/envs/RacingCar-v0/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZNiGMqsQfok"
   },
   "source": [
    "![Racing](racing_car.gif)\n",
    "\n",
    "There are five discrete **actions** in this environment:\n",
    "- left (0)\n",
    "- right (1)\n",
    "- brake (2)\n",
    "- accelerate (3)\n",
    "- none (4)\n",
    "\n",
    "**Reward** of -0.1 is awarded every frame and +1000/N for every track tile visited, where N is the total number of tiles in track. For example, if you have finished in 732 frames, your reward is 1000 - 0.1*732 = 926.8 points.\n",
    "\n",
    "And the **state** is represented using a single image frame (96 * 96)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm_TwuoRQfol"
   },
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHWFxiANQfom"
   },
   "source": [
    "If using Google colab you need to install packages - comment out lines below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XEhFeXkQfom",
    "outputId": "bff97291-199b-486f-8b75-f9dae33b9bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "swig is already the newest version (3.0.12-1).\n",
      "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "x11-utils is already the newest version (7.7+3build1).\n",
      "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
      "Requirement already satisfied: pyglet in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
      "Requirement already satisfied: box2d in /usr/local/lib/python3.7/dist-packages (2.3.10)\n",
      "Requirement already satisfied: box2d-kengz in /usr/local/lib/python3.7/dist-packages (2.3.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet) (0.16.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.11.0+cu113)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.21.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.1.2.30)\n",
      "Requirement already satisfied: ale-py~=0.7.4 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.7.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym==0.21->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (5.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym==0.21->stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.44.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n",
      "Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.7/dist-packages (3.1.6)\n",
      "Requirement already satisfied: PyOpenGL-accelerate in /usr/local/lib/python3.7/dist-packages (3.1.5)\n"
     ]
    }
   ],
   "source": [
    "!apt install swig cmake ffmpeg\n",
    "!apt-get install -y xvfb x11-utils\n",
    "!pip install stable-baselines3[extra] pyglet box2d box2d-kengz\n",
    "!pip install pyvirtualdisplay PyOpenGL PyOpenGL-accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV9IM5FRQfoo"
   },
   "source": [
    "For Google colab comment out this cell to make a virtual rendering canvas so render calls work (we still won't see display!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zh2cw7iSQfop"
   },
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "\n",
    "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
    "                                    size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8Bcx9GkQfoq"
   },
   "source": [
    "Import required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dZcWCINuQfor"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import gym\n",
    "import stable_baselines3 as sb3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import IPython\n",
    "from IPython import display as ipythondisplay\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import pandas as pd # For data frames and data frame manipulation\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "import numpy as np # For general  numeric operations\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEJsAysfQfos"
   },
   "source": [
    "### Create and Explore the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCMqLB1VQfot"
   },
   "source": [
    "Create the **CarRacing-v0** environment. Add wrappers to resize the images and convert to greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w7xkqRzcQfot"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "env = gym.wrappers.resize_observation.ResizeObservation(env, 64)\n",
    "env = gym.wrappers.gray_scale_observation.GrayScaleObservation(env, keep_dim = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9BQTzRKQfou"
   },
   "source": [
    "Explore the environment - view the action space and observation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "peo_ntRkQfou",
    "outputId": "063caa9c-f0d4-4a36-ff99-f0ed41ab92af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], [1. 1. 1.], (3,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgObNy4uQfov",
    "outputId": "8addedf3-bd22-4a80-eb49-d6b7af4bd241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]\n",
       "\n",
       " [[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]\n",
       "\n",
       " [[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]\n",
       "\n",
       " [[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]\n",
       "\n",
       " [[0]\n",
       "  [0]\n",
       "  [0]\n",
       "  ...\n",
       "  [0]\n",
       "  [0]\n",
       "  [0]]], [[[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]\n",
       "\n",
       " [[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]\n",
       "\n",
       " [[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]\n",
       "\n",
       " [[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]\n",
       "\n",
       " [[255]\n",
       "  [255]\n",
       "  [255]\n",
       "  ...\n",
       "  [255]\n",
       "  [255]\n",
       "  [255]]], (64, 64, 1), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-QsvRe0Qfow"
   },
   "source": [
    "Play an episode of the environment using random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_jvIhrjQfox",
    "outputId": "2bcf4e34-f09a-4b83-ef50-2fe1f647e668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1177..1476 -> 299-tiles track\n",
      "Episode Number:0, Score awarded:-32.885906040268935\n",
      "Track generation: 1209..1516 -> 307-tiles track\n",
      "Episode Number:1, Score awarded:-34.640522875817524\n",
      "Track generation: 1091..1368 -> 277-tiles track\n",
      "Episode Number:2, Score awarded:-27.536231884058182\n",
      "Track generation: 1487..1863 -> 376-tiles track\n",
      "Episode Number:3, Score awarded:-46.666666666667446\n",
      "Track generation: 1019..1285 -> 266-tiles track\n",
      "Episode Number:4, Score awarded:-24.52830188679274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for episode in range(5):\n",
    "    score = 0\n",
    "    done = False\n",
    "    state = env.reset() # return an initial observation\n",
    "    \n",
    "    # Starting the process using random actions\n",
    "    while not done:\n",
    "        # These steps have been tested in google colab ( might not work in jupyter notebook)\n",
    "        # start\n",
    "        #screen = env.render(mode = 'rgb_array')\n",
    "        #plt.imshow(screen)\n",
    "        #ipythondisplay.clear_output(wait = True)\n",
    "        #ipythondisplay.display(plt.gcf())\n",
    "        # end\n",
    "        action = env.action_space.sample()  # Agent choosing an action randomly\n",
    "        n_state,reward,done,info = env.step(action) # returning observation set, reward and completeness state\n",
    "        score += reward\n",
    "        \n",
    "    print(\"Episode Number:{}, Score awarded:{}\".format(episode,score))\n",
    "    \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ml3JnJ5Qfox"
   },
   "source": [
    "###Â Single Image Agent\n",
    "Create an agent that controls the car using a single image frame as the state input. We recommend a PPO agent with the following hyper-parameters (although you can experiment):\n",
    "- learning_rate = 3e-5\n",
    "- n_steps = 512\n",
    "- ent_coef = 0.001\n",
    "- batch_size = 128\n",
    "- gae_lambda =  0.9\n",
    "- n_epochs = 20\n",
    "- use_sde = True\n",
    "- sde_sample_freq = 4\n",
    "- clip_range = 0.4\n",
    "- policy_kwargs = {'log_std_init': -2, 'ortho_init':False},\n",
    "\n",
    "We also recommend enabling **tensorboard** monitoring of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MCiDsWMov_ao"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "env = DummyVecEnv([lambda:env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GHY19WhjQfoy",
    "outputId": "f1e62905-49ad-408c-cda4-4fca4b4cc1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Setting the path to record logs\n",
    "log_path = os.path.join('logs_carracing_PPO','Logs')\n",
    "\n",
    "# PPO Agent creation using CNN Policy\n",
    "agentModel = PPO('CnnPolicy', env, verbose = 1, tensorboard_log = log_path, learning_rate = 3e-5, n_steps = 512, \n",
    "                 ent_coef = 0.001, batch_size = 128, gae_lambda = 0.9, n_epochs = 20, use_sde = True, \n",
    "                 sde_sample_freq = 4, clip_range = 0.4, policy_kwargs = {'log_std_init': -2, 'ortho_init':False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaVvGXkNQfoz"
   },
   "source": [
    "Examine the actor and critic network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNjosaimQfoz",
    "outputId": "d56fd4d8-cea6-4902-f244-53f44a7ccb9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentModel.policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdRpUwTeQfoz"
   },
   "source": [
    "Create an evaluation callback that is called every at regular intervals and renders the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oulh4r78Qfoz"
   },
   "outputs": [],
   "source": [
    "eval_env = gym.make('CarRacing-v0')\n",
    "eval_callback = sb3.common.callbacks.EvalCallback(eval_env, \n",
    "                                                  best_model_save_path = './logs_carracing_PPO/',\n",
    "                                                  log_path = './logs_carracing_PPO/', \n",
    "                                                  eval_freq = 5000,\n",
    "                                                  render = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMj3hpimQfo0"
   },
   "source": [
    "Train the model for a large number of timesteps (500,000 timesteps will probably work well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNtGLDLUQfo0",
    "outputId": "88e7e9f3-96a3-491e-d565-aa20d030e923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1042..1313 -> 271-tiles track\n",
      "Logging to logs_carracing_PPO/Logs/Single Image Agent Network_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/callbacks.py:345: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f92b8329e90> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f92c76be6d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 69  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 7   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "Track generation: 962..1215 -> 253-tiles track\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 48        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 1024      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7076732 |\n",
      "|    clip_fraction        | 0.47      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | 2.54      |\n",
      "|    explained_variance   | 6.18e-05  |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.603     |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | 0.00843   |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 1.03      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 43        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 1536      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7804889 |\n",
      "|    clip_fraction        | 0.5       |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | 1.26      |\n",
      "|    explained_variance   | 0.017     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 1.02      |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0478   |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 2.42      |\n",
      "---------------------------------------\n",
      "Track generation: 1148..1439 -> 291-tiles track\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 41        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.1029582 |\n",
      "|    clip_fraction        | 0.734     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -2.94     |\n",
      "|    explained_variance   | 0.0681    |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.639     |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | 0.174     |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 1.66      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 40         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21228018 |\n",
      "|    clip_fraction        | 0.526      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.47      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.0695     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0479    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.439      |\n",
      "----------------------------------------\n",
      "Track generation: 1116..1399 -> 283-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 77         |\n",
      "|    total_timesteps      | 3072       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08635925 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.68      |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.00224    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 3584       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13502349 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.1       |\n",
      "|    explained_variance   | 0.702      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.252      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.562      |\n",
      "----------------------------------------\n",
      "Track generation: 1165..1460 -> 295-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10390464 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.41      |\n",
      "|    explained_variance   | 0.89       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.0453     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0282    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07262458 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.42      |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.198      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0647    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.757      |\n",
      "----------------------------------------\n",
      "Track generation: 1064..1334 -> 270-tiles track\n",
      "Track generation: 1232..1544 -> 312-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "Track generation: 1081..1355 -> 274-tiles track\n",
      "Track generation: 1187..1488 -> 301-tiles track\n",
      "Track generation: 1020..1284 -> 264-tiles track\n",
      "Track generation: 1129..1415 -> 286-tiles track\n",
      "Eval num_timesteps=5000, episode_reward=-82.67 +/- 1.13\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -82.7       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040646125 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.0538     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 22   |\n",
      "|    iterations      | 10   |\n",
      "|    time_elapsed    | 228  |\n",
      "|    total_timesteps | 5120 |\n",
      "-----------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 23       |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 243      |\n",
      "|    total_timesteps      | 5632     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.143351 |\n",
      "|    clip_fraction        | 0.196    |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -7.12    |\n",
      "|    explained_variance   | 0.355    |\n",
      "|    learning_rate        | 3e-05    |\n",
      "|    loss                 | 0.537    |\n",
      "|    n_updates            | 200      |\n",
      "|    policy_gradient_loss | -0.00778 |\n",
      "|    std                  | 0.135    |\n",
      "|    value_loss           | 1.86     |\n",
      "--------------------------------------\n",
      "Track generation: 1236..1549 -> 313-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 258        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08070196 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -7.42      |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.099      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0373    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.537      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 273        |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15926923 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -7.49      |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.357      |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0424    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.39       |\n",
      "----------------------------------------\n",
      "Track generation: 1214..1521 -> 307-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 288        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10483505 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -7.49      |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.16       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.773      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056509513 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.84       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.374       |\n",
      "-----------------------------------------\n",
      "Track generation: 1036..1300 -> 264-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 25          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036816765 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.0693      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 26         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 8704       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07850167 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -7.79      |\n",
      "|    explained_variance   | 0.658      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.893      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0549    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 2.47       |\n",
      "----------------------------------------\n",
      "Track generation: 1124..1409 -> 285-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043437272 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.82       |\n",
      "|    explained_variance   | -0.248      |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.083033204 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.97       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.601       |\n",
      "-----------------------------------------\n",
      "Track generation: 1155..1448 -> 293-tiles track\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 1060..1329 -> 269-tiles track\n",
      "Track generation: 1187..1488 -> 301-tiles track\n",
      "Track generation: 1083..1358 -> 275-tiles track\n",
      "Track generation: 1014..1279 -> 265-tiles track\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "Eval num_timesteps=10000, episode_reward=-0.38 +/- 10.54\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -0.381      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101017386 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.7        |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0601     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 21    |\n",
      "|    iterations      | 20    |\n",
      "|    time_elapsed    | 472   |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 487        |\n",
      "|    total_timesteps      | 10752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07429646 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.12      |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.732      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.92       |\n",
      "----------------------------------------\n",
      "Track generation: 1083..1359 -> 276-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 503        |\n",
      "|    total_timesteps      | 11264      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18089332 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.85      |\n",
      "|    explained_variance   | 0.894      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.425      |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.66       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 518        |\n",
      "|    total_timesteps      | 11776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06365277 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.34      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.386      |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0457    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "Track generation: 1164..1458 -> 294-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 534        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03494066 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.94      |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.14       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0456    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.668      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 549        |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03289365 |\n",
      "|    clip_fraction        | 0.0709     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.99      |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.594      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 2.01       |\n",
      "----------------------------------------\n",
      "Track generation: 1064..1340 -> 276-tiles track\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 23        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 564       |\n",
      "|    total_timesteps      | 13312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0287975 |\n",
      "|    clip_fraction        | 0.0583    |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -9.17     |\n",
      "|    explained_variance   | -0.266    |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.0381    |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | -0.00533  |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 0.469     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042708624 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -8.82       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027090624 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -8.9        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0873      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.561       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 609        |\n",
      "|    total_timesteps      | 14848      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06630589 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.34      |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.323      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | 0.0063     |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "Track generation: 1081..1355 -> 274-tiles track\n",
      "Track generation: 1001..1263 -> 262-tiles track\n",
      "Track generation: 1080..1354 -> 274-tiles track\n",
      "Track generation: 1043..1308 -> 265-tiles track\n",
      "Track generation: 1136..1424 -> 288-tiles track\n",
      "Track generation: 1232..1547 -> 315-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1044..1316 -> 272-tiles track\n",
      "Track generation: 1084..1359 -> 275-tiles track\n",
      "Eval num_timesteps=15000, episode_reward=4.22 +/- 13.65\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 4.22       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 15000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04149173 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.14      |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.288      |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.05       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 21    |\n",
      "|    iterations      | 30    |\n",
      "|    time_elapsed    | 720   |\n",
      "|    total_timesteps | 15360 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 734         |\n",
      "|    total_timesteps      | 15872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025547534 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.06       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.652       |\n",
      "-----------------------------------------\n",
      "Track generation: 1163..1458 -> 295-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050010003 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -8.98       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.489       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052459262 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.48       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "Track generation: 1063..1336 -> 273-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 779        |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08654013 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.03      |\n",
      "|    explained_variance   | 0.789      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.15       |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0671    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.967      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 793        |\n",
      "|    total_timesteps      | 17920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03465572 |\n",
      "|    clip_fraction        | 0.0529     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.52      |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.413      |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.14       |\n",
      "----------------------------------------\n",
      "Track generation: 1145..1435 -> 290-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 808        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08875357 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.94      |\n",
      "|    explained_variance   | -0.14      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | -0.0374    |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0511    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.0944     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 822        |\n",
      "|    total_timesteps      | 18944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03870345 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.49      |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.477      |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.51       |\n",
      "----------------------------------------\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 23         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 836        |\n",
      "|    total_timesteps      | 19456      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04318736 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.3       |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.16       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0432    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.666      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042068392 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.45       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "Track generation: 1160..1454 -> 294-tiles track\n",
      "Track generation: 1145..1441 -> 296-tiles track\n",
      "Track generation: 1285..1610 -> 325-tiles track\n",
      "Track generation: 1063..1333 -> 270-tiles track\n",
      "Track generation: 1232..1546 -> 314-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1106..1393 -> 287-tiles track\n",
      "Track generation: 1033..1300 -> 267-tiles track\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Eval num_timesteps=20000, episode_reward=-82.55 +/- 1.22\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -82.6       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029238943 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.68       |\n",
      "|    explained_variance   | -0.0493     |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0127      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.0538      |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 21    |\n",
      "|    iterations      | 40    |\n",
      "|    time_elapsed    | 962   |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 977        |\n",
      "|    total_timesteps      | 20992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06341216 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.53      |\n",
      "|    explained_variance   | 0.802      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.0637     |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0455    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.398      |\n",
      "----------------------------------------\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 992         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043847423 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.64       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.0895      |\n",
      "-----------------------------------------\n",
      "Track generation: 1186..1484 -> 298-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1006        |\n",
      "|    total_timesteps      | 22016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053147405 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.78       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0784      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037983518 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.95       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0577      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.0934      |\n",
      "-----------------------------------------\n",
      "Track generation: 1276..1599 -> 323-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1036        |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056359507 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.92       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 1052       |\n",
      "|    total_timesteps      | 23552      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07403349 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.896      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | -0.0521    |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0347    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.214      |\n",
      "----------------------------------------\n",
      "Track generation: 1110..1397 -> 287-tiles track\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 24064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029446226 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.8        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.00446    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.377       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050123475 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.635       |\n",
      "-----------------------------------------\n",
      "Track generation: 953..1201 -> 248-tiles track\n",
      "Track generation: 1170..1475 -> 305-tiles track\n",
      "Track generation: 1116..1399 -> 283-tiles track\n",
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "Track generation: 1132..1430 -> 298-tiles track\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 1246..1562 -> 316-tiles track\n",
      "Eval num_timesteps=25000, episode_reward=-36.02 +/- 17.11\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | -36        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07610797 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -10.2      |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | -0.0343    |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.0584    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 21    |\n",
      "|    iterations      | 49    |\n",
      "|    time_elapsed    | 1192  |\n",
      "|    total_timesteps | 25088 |\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f92b8329b10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentModel.learn(total_timesteps = 25000, callback = eval_callback, \n",
    "                 tb_log_name = \"Single Image Agent Network\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24RlrYF7Qfo0"
   },
   "source": [
    "Connect to the tensorboard log using **TensorBoard** from the command line to view training progress: \n",
    "\n",
    "`tensorboard --logdir ./logs_carracing_PPO/`\n",
    "\n",
    "Then open TensorBoard in a browser, typically located at:\n",
    "\n",
    "`http://localhost:6006/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nir4ZmnqQfo1"
   },
   "source": [
    "Save the trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBGtMv04Qfo1",
    "outputId": "f5f0548e-72e6-40c6-8363-9a431961809c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'logs_carracing_PPO/Saved_Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Path to save single agent model\n",
    "single_agent_path = os.path.join('logs_carracing_PPO','Saved_Models','singleAgentPPO_model')\n",
    "agentModel.save(single_agent_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxs3h7Owre5T"
   },
   "source": [
    "For memory management delete old agent and environment (assumes variable names - change if required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uOGiJDrTrdV3"
   },
   "outputs": [],
   "source": [
    "del agentModel\n",
    "del env\n",
    "del eval_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQF_FjMEQfo1"
   },
   "source": [
    "###Â Create Image Stack Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMn23o_xs_rm"
   },
   "source": [
    "Create the CarRacing-v0 environment using wrappers to resize the images to 64 x 64 and change to greyscale. Also add a wrapper to create a stack of 4 frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ijzQwZY0Qfo2"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "#env = gym.wrappers.resize_observation.ResizeObservation(env, 64)\n",
    "#env = gym.wrappers.gray_scale_observation.GrayScaleObservation(env, keep_dim = True)\n",
    "\n",
    "# Creating Stack of four frames\n",
    "#env = DummyVecEnv([lambda:env])\n",
    "env = sb3.common.env_util.make_vec_env('CarRacing-v0',n_envs=1,seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77o0YzOmQfo2"
   },
   "source": [
    "Create an agent that controls the car using a stack of input image frames as the state input. We recommend a PPO agent with the following hyper-parameters (although you can experiment):\n",
    "- learning_rate = 3e-5\n",
    "- n_steps = 512\n",
    "- ent_coef = 0.001\n",
    "- batch_size = 128\n",
    "- gae_lambda =  0.9\n",
    "- n_epochs = 20\n",
    "- use_sde = True\n",
    "- sde_sample_freq = 4\n",
    "- clip_range = 0.4\n",
    "- policy_kwargs = {'log_std_init': -2, 'ortho_init':False},\n",
    "\n",
    "We also recommend enabling **tensorboard** monitoring of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aAxmNANQfo2",
    "outputId": "26732aac-1a59-4292-e722-528c597b2c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Setting the path to record logs\n",
    "log_path = os.path.join('log_tb_carracing_PPO','Logs')\n",
    "\n",
    "# PPO Agent creation using CNN Policy\n",
    "agentModel = PPO('CnnPolicy', env, verbose=1, tensorboard_log = log_path, learning_rate = 3e-5, n_steps = 512, \n",
    "          ent_coef = 0.001, batch_size = 128, gae_lambda = 0.9, n_epochs = 20, use_sde = True, \n",
    "          sde_sample_freq = 4, clip_range = 0.4, policy_kwargs = {'log_std_init': -2, 'ortho_init':False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkOXkC-HQfo2"
   },
   "source": [
    "Examine the actor and critic network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fS-fpmWwQfo3",
    "outputId": "0b8edb09-63a3-4c3a-b1ef-b9cf046ede5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(12, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentModel.policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1jObjvdQfo3"
   },
   "source": [
    "Create an evaluation callback that is called every at regular intervals and renders the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aL2c4LiOQfo4"
   },
   "outputs": [],
   "source": [
    "#eval_env = gym.make('CarRacing-v0')\n",
    "stop_callback = sb3.common.callbacks.StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = sb3.common.callbacks.EvalCallback(env, \n",
    "                                                  callback_on_new_best=stop_callback,\n",
    "                                                  best_model_save_path='./log_tb_carracing_PPO/',\n",
    "                                                  log_path='./log_tb_carracing_PPO/', \n",
    "                                                  eval_freq=10000,\n",
    "                                                  render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s33dR-mgQfo4"
   },
   "source": [
    "Train the model for a large number of timesteps (500,000 timesteps will probably work well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BD585g86hpmQ",
    "outputId": "c36b81fc-036c-45b0-b4f5-53e34e9464d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n",
      "Logging to log_tb_carracing_PPO/Logs/Image Stack Agent Network_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/callbacks.py:345: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f92398e34d0> != <stable_baselines3.common.vec_env.vec_frame_stack.VecFrameStack object at 0x7f92398e3210>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 98  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 5   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "Track generation: 1087..1369 -> 282-tiles track\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -59.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 33        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 1024      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8567095 |\n",
      "|    clip_fraction        | 0.491     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | 2.79      |\n",
      "|    explained_variance   | 0.000721  |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.477     |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | 0.053     |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 0.991     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -59.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 1536      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4151895 |\n",
      "|    clip_fraction        | 0.857     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -2.44     |\n",
      "|    explained_variance   | 0.12      |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.109     |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | 0.0747    |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 0.16      |\n",
      "---------------------------------------\n",
      "Track generation: 964..1212 -> 248-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -69.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 25        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7047465 |\n",
      "|    clip_fraction        | 0.598     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -3.54     |\n",
      "|    explained_variance   | 0.297     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.0978    |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -0.00949  |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 0.368     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -69.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 24         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 2560       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30099753 |\n",
      "|    clip_fraction        | 0.545      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -5.02      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | -0.111     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0543    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.086      |\n",
      "----------------------------------------\n",
      "Track generation: 1283..1608 -> 325-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -70.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054023683 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -70.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 156        |\n",
      "|    total_timesteps      | 3584       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20071512 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -5.32      |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.176      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.251      |\n",
      "----------------------------------------\n",
      "Track generation: 1217..1526 -> 309-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -71.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.111031726 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0478     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -71.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09549545 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -5.78      |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0379    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -72.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056720614 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -5.93       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -72.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 256         |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038378254 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -6.16       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0444     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.316       |\n",
      "-----------------------------------------\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -73.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047584165 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.0392     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -73.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053066764 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -6.11       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.0224      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0613     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.369       |\n",
      "-----------------------------------------\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -73.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 330        |\n",
      "|    total_timesteps      | 7168       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05818344 |\n",
      "|    clip_fraction        | 0.0765     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.53      |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.0237     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.144      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -73.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 21        |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 355       |\n",
      "|    total_timesteps      | 7680      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0871126 |\n",
      "|    clip_fraction        | 0.149     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -6.81     |\n",
      "|    explained_variance   | 0.934     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | -0.0654   |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.0555   |\n",
      "|    std                  | 0.135     |\n",
      "|    value_loss           | 0.118     |\n",
      "---------------------------------------\n",
      "Track generation: 957..1205 -> 248-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -74.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 380        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07497346 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.89      |\n",
      "|    explained_variance   | 0.295      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.0365    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.206      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -74.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 405        |\n",
      "|    total_timesteps      | 8704       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08069754 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.83      |\n",
      "|    explained_variance   | 0.76       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.249      |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0434    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 0.557      |\n",
      "----------------------------------------\n",
      "Track generation: 1181..1480 -> 299-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -54.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 429        |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11331026 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.02      |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.38       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 3.68       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -54.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 9728       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09432052 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.49      |\n",
      "|    explained_variance   | -0.364     |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.663      |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.135      |\n",
      "|    value_loss           | 1.55       |\n",
      "----------------------------------------\n",
      "Track generation: 979..1234 -> 255-tiles track\n",
      "Track generation: 1320..1654 -> 334-tiles track\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "Track generation: 1106..1396 -> 290-tiles track\n",
      "Track generation: 1296..1628 -> 332-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1047..1319 -> 272-tiles track\n",
      "Eval num_timesteps=10000, episode_reward=30.39 +/- 9.80\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+03      |\n",
      "|    mean_reward          | 30.4       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 10000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18070057 |\n",
      "|    clip_fraction        | 0.376      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -6.47      |\n",
      "|    explained_variance   | 0.605      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.349      |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0823    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.815      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -48.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 574      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -48.2     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 17        |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 598       |\n",
      "|    total_timesteps      | 10752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5604288 |\n",
      "|    clip_fraction        | 0.576     |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -7.42     |\n",
      "|    explained_variance   | 0.542     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.568     |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | 0.0461    |\n",
      "|    std                  | 0.134     |\n",
      "|    value_loss           | 1.38      |\n",
      "---------------------------------------\n",
      "Track generation: 1245..1560 -> 315-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099553496 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.043      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.049      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.253       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.100664765 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -7.96       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.84        |\n",
      "-----------------------------------------\n",
      "Track generation: 1232..1544 -> 312-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -37        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 674        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09158548 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.25      |\n",
      "|    explained_variance   | 0.562      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.568      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0239    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.97       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -37        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05946517 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.39      |\n",
      "|    explained_variance   | 0.626      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.87       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0629    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 2.45       |\n",
      "----------------------------------------\n",
      "Track generation: 1120..1408 -> 288-tiles track\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1e+03     |\n",
      "|    ep_rew_mean          | -34.9     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 18        |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 724       |\n",
      "|    total_timesteps      | 13312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0506814 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.4       |\n",
      "|    entropy_loss         | -8.5      |\n",
      "|    explained_variance   | 0.471     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 0.325     |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | -0.0512   |\n",
      "|    std                  | 0.134     |\n",
      "|    value_loss           | 1.19      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -34.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 750        |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08384233 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -8.69      |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.27       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 0.94       |\n",
      "----------------------------------------\n",
      "Track generation: 1225..1536 -> 311-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -32.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055603765 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.08       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.987       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -32.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078644976 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.22       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.065      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "Track generation: 1077..1357 -> 280-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -28.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 826        |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11176354 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.32      |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.569      |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0469    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 2.28       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -28.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 851        |\n",
      "|    total_timesteps      | 15872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08503283 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -9.48      |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.417      |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.033     |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.52       |\n",
      "----------------------------------------\n",
      "Track generation: 1322..1664 -> 342-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -25.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 875         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044216417 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -9.76       |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.373       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -25.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 900        |\n",
      "|    total_timesteps      | 16896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06367582 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -10        |\n",
      "|    explained_variance   | 0.735      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.566      |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.00729   |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.75       |\n",
      "----------------------------------------\n",
      "Track generation: 1035..1297 -> 262-tiles track\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | -21.5    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 18       |\n",
      "|    iterations           | 34       |\n",
      "|    time_elapsed         | 924      |\n",
      "|    total_timesteps      | 17408    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.041504 |\n",
      "|    clip_fraction        | 0.0347   |\n",
      "|    clip_range           | 0.4      |\n",
      "|    entropy_loss         | -10.2    |\n",
      "|    explained_variance   | 0.818    |\n",
      "|    learning_rate        | 3e-05    |\n",
      "|    loss                 | 0.0704   |\n",
      "|    n_updates            | 660      |\n",
      "|    policy_gradient_loss | -0.0239  |\n",
      "|    std                  | 0.134    |\n",
      "|    value_loss           | 0.779    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -21.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060547803 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "Track generation: 1297..1626 -> 329-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -16.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 974        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07936157 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -10.9      |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.1        |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 3.46       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -16.1      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 998        |\n",
      "|    total_timesteps      | 18944      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03508019 |\n",
      "|    clip_fraction        | 0.0658     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -10.9      |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.487      |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 1.29       |\n",
      "----------------------------------------\n",
      "Track generation: 1294..1621 -> 327-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -9.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1023        |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057025876 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -9.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1047        |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036945686 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 4.45        |\n",
      "-----------------------------------------\n",
      "Track generation: 1055..1331 -> 276-tiles track\n",
      "Track generation: 1202..1507 -> 305-tiles track\n",
      "Track generation: 863..1087 -> 224-tiles track\n",
      "Track generation: 1227..1538 -> 311-tiles track\n",
      "Track generation: 1317..1652 -> 335-tiles track\n",
      "Track generation: 1115..1402 -> 287-tiles track\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "Eval num_timesteps=20000, episode_reward=118.17 +/- 21.57\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 118         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024564473 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.4       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.807       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -9.23    |\n",
      "| time/              |          |\n",
      "|    fps             | 17       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1168     |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -9.23      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 1192       |\n",
      "|    total_timesteps      | 20992      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04808733 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -11.2      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.476      |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0397    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 2.2        |\n",
      "----------------------------------------\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -5.64      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1217       |\n",
      "|    total_timesteps      | 21504      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11373423 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -11.4      |\n",
      "|    explained_variance   | 0.738      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.06       |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0288    |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 3.9        |\n",
      "----------------------------------------\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1242        |\n",
      "|    total_timesteps      | 22016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052115627 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.561       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 2.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1266        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025168788 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.7       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.82        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "Track generation: 1260..1579 -> 319-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1291        |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044827797 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.6       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 5.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1316        |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037626147 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.5       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n",
      "Track generation: 1100..1379 -> 279-tiles track\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | 4.76       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 1342       |\n",
      "|    total_timesteps      | 24064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07139815 |\n",
      "|    clip_fraction        | 0.0951     |\n",
      "|    clip_range           | 0.4        |\n",
      "|    entropy_loss         | -11.8      |\n",
      "|    explained_variance   | 0.676      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 0.881      |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.00203   |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 3.54       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 4.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1367        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025545875 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.8       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | 0.00408     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "Track generation: 1185..1485 -> 300-tiles track\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 6.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1392        |\n",
      "|    total_timesteps      | 25088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059337556 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.4         |\n",
      "|    entropy_loss         | -11.9       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0276     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 3.54        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f92398e3990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentModel.learn(total_timesteps = 25000, callback = eval_callback, \n",
    "                 tb_log_name = \"Image Stack Agent Network\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sotpjktQfo4"
   },
   "source": [
    "Connect to the tensorboard log using **TensorBoard** from the command line to view training progress: \n",
    "\n",
    "`tensorboard --logdir ./log_tb_carracing_PPO/`\n",
    "\n",
    "Then open TensorBoard in a browser, typically located at:\n",
    "\n",
    "`http://localhost:6006/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8j9GrTTQfo5"
   },
   "source": [
    "Save the trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8ivh_VpQfo5",
    "outputId": "5edcbac0-b108-4bb5-ccc9-9940b9f434fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/save_util.py:276: UserWarning: Path 'log_tb_carracing_PPO/Saved_Models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    }
   ],
   "source": [
    "# Path to save image stack agent model\n",
    "stackAgent_path = os.path.join('log_tb_carracing_PPO','Saved_Models','stackAgentPPO_model')\n",
    "agentModel.save(stackAgent_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erpc33nws_ro"
   },
   "source": [
    "For memory management delete old agent and environment (assumes variable names - change if required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Cv-6UuSRs_ro"
   },
   "outputs": [],
   "source": [
    "del agentModel\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWZrzrZ3Qfo5"
   },
   "source": [
    "###Â Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRzc_-yOQfo5"
   },
   "source": [
    "Load the single image saved agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XyfQmsF6Qfo6"
   },
   "outputs": [],
   "source": [
    "agentModel = PPO.load(single_agent_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWaj7pBOs_ro"
   },
   "source": [
    "Setup the single image environment for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TR_NsW6ms_ro"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "env = DummyVecEnv([lambda:env])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8X8r5S5Qfo6"
   },
   "source": [
    "Evaluate the agent in the environment for 30 episodes, rendering the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrMN5vOeQfo6",
    "outputId": "5d37391a-998e-421d-9b7a-e8e820f5dbc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1172..1469 -> 297-tiles track\n",
      "Track generation: 1060..1338 -> 278-tiles track\n",
      "Track generation: 1118..1403 -> 285-tiles track\n",
      "Track generation: 1087..1365 -> 278-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1112..1394 -> 282-tiles track\n",
      "Track generation: 1363..1707 -> 344-tiles track\n",
      "Track generation: 1184..1484 -> 300-tiles track\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "Track generation: 1138..1427 -> 289-tiles track\n",
      "Track generation: 1201..1512 -> 311-tiles track\n",
      "Track generation: 1326..1662 -> 336-tiles track\n",
      "Track generation: 1043..1306 -> 263-tiles track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-31.49887722209096, 13.147621395486937)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(agentModel, env, n_eval_episodes=30, render=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6K6TXdCQfo6"
   },
   "source": [
    "For memory management delete the single image agent (assumes variable names - change if required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yAeeHAKVQfo6"
   },
   "outputs": [],
   "source": [
    "del agentModel\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1y0UngLQfo6"
   },
   "source": [
    "Load the image stack agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lCxi6SvMQfo7"
   },
   "outputs": [],
   "source": [
    "agentModel = PPO.load(stackAgent_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIsa2MDps_rp"
   },
   "source": [
    "Set up the image stack environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tPIbiuOAs_rp"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "#env = gym.wrappers.resize_observation.ResizeObservation(env, 64)\n",
    "#env = gym.wrappers.gray_scale_observation.GrayScaleObservation(env, keep_dim = True)\n",
    "\n",
    "#env = DummyVecEnv([lambda:env])\n",
    "env = sb3.common.env_util.make_vec_env('CarRacing-v0',n_envs=1,seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tr8lGKjpQfo7"
   },
   "source": [
    "Evaluate the agent in the environment for 30 episodes, rendering the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgbbH_UkQfo7",
    "outputId": "a7a38ace-05c9-4983-c702-435da806cf1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n",
      "Track generation: 1087..1369 -> 282-tiles track\n",
      "Track generation: 964..1212 -> 248-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "Track generation: 1283..1608 -> 325-tiles track\n",
      "Track generation: 1217..1526 -> 309-tiles track\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "Track generation: 957..1205 -> 248-tiles track\n",
      "Track generation: 1181..1480 -> 299-tiles track\n",
      "Track generation: 979..1234 -> 255-tiles track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-17.695962399999996, 31.027389355649106)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(agentModel, env, n_eval_episodes=30, render=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxw2MRZcs_rp"
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRCxNiPqQfo7"
   },
   "source": [
    "Reflect on which  agent performs better at the task, and the training process involved (max 200 words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPxa3a7-8f-q"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZqHm6SKs_rq"
   },
   "source": [
    "I trained both the agents through `PPO` because it is well suited to our environment action space which is of type box while `DQN` cannot be used for box type action space. `PPO` takes less time and give best results because it tries to simplify and directly optimize the policy. Algorithm that I have used here is `CNNPolicy` rather than `mlpPolicy` because it is more suited to image data and works well with spatial relationship data while MLP works better with tabular data.\n",
    "\n",
    "In terms of the __agent performance__, __Image Stack Agent__ works better than the __Single Image Agent__ as per the rendering screen generated on training the models on 0.5M timesteps because it is building on 4 environments per step and in general it allows for n environments per step. This improves the accuracy and increases it's speed. Not only this, it converts the action space which is being sent to the environment into multidimensional vector. Single Image agent on the other hand works on one environment per step hence the speed and accuracy suffers. \n",
    "\n",
    "I used Google Colab to train and evaluate the agents. Since 0.5M timesteps was taking a lot of time to run due to the system configurations, so I am showcasing the results from the 25K timesteps for Single Image and 25K timesteps for Image Stack agents where the evaluation results show that Image stack agents works far better than the single image agent. I evaluated the results for 0.2M and 0.1M timesteps for both the agents where Image Stack was rewarded better points in every case.\n",
    "\n",
    "For single image agent the reward was -31 with 13 as variance when trained on 25K timesteps but it resulted in 200-300 reward points when trained on 0.1 to 0.2M timesteps.\n",
    "\n",
    "For Image stack agent, the reward was -17 with 31 as variance when trained on 25K timesteps but it resulted in 300-400 reward points when trained on 0.1 to 0.2M timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k6ySW3l8s_rq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook COMP47590_Assignment_2_Going_The_Distance_d.ipynb to html\n",
      "[NbConvertApp] Writing 731222 bytes to COMP47590_Assignment_2_Going_The_Distance_d.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html COMP47590_Assignment_2_Going_The_Distance_d.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "COMP47590 Assignment 2 Going The Distance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.571px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
